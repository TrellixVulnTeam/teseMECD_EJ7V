{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lxmert_features.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#from PIL import Image\n",
        "#import requests\n",
        "#requests.__version__\n",
        "#!pip install requests==2.27.1\n",
        "!pip install transformers\n",
        "!pip install wget\n",
        "!pip install lmdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb0ph0VZSpu-",
        "outputId": "ea881a12-24aa-407a-dde5-9d25e762ea74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (0.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C6OYval8z57_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd5a50f-c147-493e-f105-1d6f5323fd1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath('/content/drive/MyDrive/teses/tese_MECD/implementation'))"
      ],
      "metadata": {
        "id": "i3qNzGu1rNn4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/teses/tese_MECD/implementation'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJxeT39EFCsv",
        "outputId": "baf408dd-c5b1-4df0-b1a6-0736e755dfe8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/teses/tese_MECD/implementation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#url = \"./data/flickr30k_images/flickr30k_images/5897297135.jpg\"\n",
        "#os.path.isfile(url)\n",
        "#os.path.isfile('./data/flickr30k_images/flickr30k_images/4852389235.jpg')\n",
        "#image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")"
      ],
      "metadata": {
        "id": "KBVe8SacTipw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import LxmertTokenizer, LxmertConfig, LxmertModel\n",
        "from modeling_frcnn import GeneralizedRCNN\n",
        "import utils\n",
        "from processing_image import Preprocess\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "import lmdb\n",
        "import pickle"
      ],
      "metadata": {
        "id": "jeQR8UHvrOAx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,path):\n",
        "        self.path = path\n",
        "        self.size = self.getSize()\n",
        "        self.env = lmdb.open(\n",
        "            path, readonly=True, create=False, readahead=not False\n",
        "        )\n",
        "        self.txn = self.env.begin(buffers=True)\n",
        "    \n",
        "    def getSize(self):\n",
        "        env = lmdb.open(self.path, readonly=True)\n",
        "        stats = env.stat()\n",
        "        count = stats['entries']\n",
        "        env.close()\n",
        "        return count\n",
        "            \n",
        "    def deserializeItem(self,item):\n",
        "        item = pickle.loads(item)\n",
        "        item['input_ids']=torch.IntTensor(item['input_ids'][0])\n",
        "        item['attention_mask']=torch.IntTensor(item['attention_mask'][0])\n",
        "        item['token_type_ids']=torch.IntTensor(item['token_type_ids'][0])\n",
        "        item['normalized_boxes']=torch.FloatTensor(item['normalized_boxes'][0])\n",
        "        item['features']=torch.FloatTensor(item['features'][0])\n",
        "        return item\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.txn.get(str(idx).encode())\n",
        "        item = self.deserializeItem(item)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "    \n",
        "    def __exit__(self):\n",
        "        self.env.close()"
      ],
      "metadata": {
        "id": "mg4viCI90XBP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTrainer():\n",
        "    def __init__(self,model,train,device=None):\n",
        "        self.device = device\n",
        "        self.model = model\n",
        "        self.train = train\n",
        "\n",
        "    def train_model(self,batch_size = None, lr= None, epochs=None):\n",
        "        optimizer = AdamW(self.model.parameters(), lr=lr)\n",
        "        train_loader = DataLoader(self.train, batch_size=batch_size, shuffle=True)\n",
        "        for epoch in range(epochs):\n",
        "            for item in train_loader:\n",
        "                input_ids = item['input_ids'].to(self.device)\n",
        "                attention_mask=item['attention_mask'].to(self.device)\n",
        "                token_type_ids=item['token_type_ids'].to(self.device)\n",
        "                features = item['features'].to(self.device)\n",
        "                normalized_boxes = item['normalized_boxes'].to(self.device)\n",
        "                label = item['label'].to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model.forward(input_ids,attention_mask,token_type_ids,\n",
        "                                             features,normalized_boxes,label)\n",
        "                loss = outputs.loss\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return"
      ],
      "metadata": {
        "id": "8L7UMGYM02N1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyEvaluator():\n",
        "  def __init__(self,test):\n",
        "    self.test = test\n",
        "    pass\n",
        "    \n",
        "  def evaluate(self, X, y):\n",
        "      \"\"\"\n",
        "      X (n_examples x n_features)\n",
        "      y (n_examples): gold labels\n",
        "      \"\"\"\n",
        "      self.eval()\n",
        "      y_hat = self.predict(X)\n",
        "      n_correct = (y == y_hat).sum().item()\n",
        "      n_possible = float(y.shape[0])\n",
        "      self.train()\n",
        "      return n_correct / n_possible"
      ],
      "metadata": {
        "id": "x6eWzMzGs_MQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lxmert(LxmertModel):\n",
        "    def __init__(self,numb_labels=3):\n",
        "        super().__init__(LxmertConfig.from_pretrained(\"unc-nlp/lxmert-base-uncased\"))\n",
        "        self.config.problem_type = \"single_label_classification\"\n",
        "        self.num_labels = numb_labels\n",
        "        self.classification = torch.nn.Linear(self.config.hidden_size, self.num_labels)\n",
        "        if self.config.problem_type == \"single_label_classification\":\n",
        "          self.loss_fct = torch.nn.CrossEntropyLoss()\n",
        "          self.output_loss = lambda output,labels : self.loss_fct(output.logits.view(-1, self.num_labels), labels.view(-1)) \n",
        "        elif self.config.problem_type == \"regression\":\n",
        "          self.loss_fct = torch.nn.MSELoss()\n",
        "          if self.num_labels == 1: self.output_loss = lambda output,labels : self.loss_fct(output.logits.squeeze(), labels.squeeze())\n",
        "          else: self.output_loss =  lambda output,labels : self.loss_fct(output.logits, labels)\n",
        "        elif self.config.problem_type == \"multi_label_classification\":\n",
        "          self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
        "          self.output_loss = lambda output,labels : self.loss_fct(output.logits, labels)\n",
        "        # don't forget to init the weights for the new layers\n",
        "        self.init_weights()\n",
        "    \n",
        "    def forward(self,input_ids,attention_mask,token_type_ids,features,normalized_boxes,label):\n",
        "\n",
        "        output = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            visual_feats=features,\n",
        "            visual_pos=normalized_boxes,\n",
        "            token_type_ids=token_type_ids,\n",
        "            return_dict=True,\n",
        "            output_attentions=False,\n",
        "        )\n",
        "        \n",
        "        aux = self.classification(output.pooled_output)\n",
        "        \n",
        "        output.logits = aux\n",
        "        output.loss = self.output_loss(output, label)\n",
        "        return output\n",
        "    \n",
        "    def predict(self,X):\n",
        "      \"\"\"\n",
        "      X (n_examples x n_features)\n",
        "      \"\"\"\n",
        "      scores = model(X)  # (n_examples x n_classes)\n",
        "      predicted_labels = scores.argmax(dim=-1)  # (n_examples)\n",
        "      return predicted_labels\n",
        "\n",
        "    def save_model(self,path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "        \n",
        "    def load_model(self,path):\n",
        "        self.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "D429P3rO1zgq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#device = \"cpu\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "task = 'train'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykMFdgi72_t4",
        "outputId": "ae604976-e712-4c9d-dca7-f6fddb0194cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if task =='train':\n",
        "    model = Lxmert()\n",
        "    model = model.to(device)\n",
        "    train = MyDataset(\"/content/drive/MyDrive/teses/tese_MECD/implementation/data/my_train_db\")\n",
        "    trainer = MyTrainer(model,train,device=device)\n",
        "    print(\"-----Training Model-----\")\n",
        "    trainer.train_model(epochs=1,batch_size = 8, lr = 1e-2)\n",
        "    print('----Training finished-----')\n",
        "    model.save_model(\"/content/drive/MyDrive/teses/tese_MECD/implementation/my_model\")\n",
        "elif task =='test':\n",
        "    model = Lxmert()\n",
        "    model.load_model(\"/content/drive/MyDrive/teses/tese_MECD/implementation/my_model\")\n",
        "    trainer = MyTrainer(model,device=device)\n",
        "    output = run_example(model,train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPvyCltL3Fhy",
        "outputId": "8b25c7e1-0224-4d45-fb1d-a582a5ec7cdf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----Training Model-----\n",
            "----Training finished-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%reset\n",
        "#import gc\n",
        "#gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nAUDsM9egGP",
        "outputId": "8967e94e-3e41-4ac1-e455-75f2e6f51bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_example(model):\n",
        "    data_path = '/content/drive/MyDrive/teses/tese_MECD/implementation/data/'\n",
        "    train = pd.read_csv(data_path+'esnlive_train.csv')\n",
        "    labels_encoding = {'contradiction':0,'neutral': 1,\n",
        "                       'entailment':2}\n",
        "    train['gold_label']=train['gold_label'].apply(lambda label: labels_encoding[label])\n",
        "    img_path = data_path+'flickr30k_images/flickr30k_images/'+ train.loc[50,'Flickr30kID']#\"32542645.jpg\"\n",
        "    question = train.loc[50,'hypothesis'] #\"How many people are in the image?\"\n",
        "    label = train.loc[50,'gold_label']\n",
        "    \n",
        "    lxmert_tokenizer = LxmertTokenizer.from_pretrained(\"unc-nlp/lxmert-base-uncased\")\n",
        "    rcnn_cfg = utils.Config.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\")\n",
        "    rcnn = GeneralizedRCNN.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\", config=rcnn_cfg)\n",
        "    image_preprocess = Preprocess(rcnn_cfg)\n",
        "    \n",
        "    images, sizes, scales_yx = image_preprocess(img_path)\n",
        "    \n",
        "    #preprocess image\n",
        "    output_dict = rcnn(\n",
        "        images, \n",
        "        sizes, \n",
        "        scales_yx=scales_yx, \n",
        "        padding=\"max_detections\",\n",
        "        max_detections=rcnn_cfg.max_detections,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    \n",
        "    #preprocess text\n",
        "    inputs = lxmert_tokenizer(\n",
        "        question,\n",
        "        padding=\"max_length\",\n",
        "        max_length=20,\n",
        "        truncation=True,\n",
        "        return_token_type_ids=True,\n",
        "        return_attention_mask=True,\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    \n",
        "    #Very important that the boxes are normalized\n",
        "    normalized_boxes = output_dict.get(\"normalized_boxes\")\n",
        "    features = output_dict.get(\"roi_features\")\n",
        "    item = {'input_ids': inputs['input_ids'],\n",
        "            'attention_mask': inputs['attention_mask'],\n",
        "            'token_type_ids': inputs['token_type_ids'],\n",
        "            'features':features, \n",
        "            'normalized_boxes':normalized_boxes, \n",
        "            'label':torch.LongTensor([label])}\n",
        "    output = model.forward(inputs['input_ids'],inputs['attention_mask'],inputs['token_type_ids'],\n",
        "                          features,normalized_boxes,torch.LongTensor([label]))\n",
        "    m = torch.nn.Softmax(dim=1)\n",
        "    probs = m(output.logits)\n",
        "    print(img_path)\n",
        "    print(question)\n",
        "    print(label)\n",
        "    print(probs)\n",
        "    return output\n",
        "\n",
        "run_example(model)"
      ],
      "metadata": {
        "id": "uC3nwfhOHPeD"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}