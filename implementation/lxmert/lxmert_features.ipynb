{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vb0ph0VZSpu-",
    "outputId": "28bb498e-b3be-46fb-d98c-523207db72ab"
   },
   "outputs": [],
   "source": [
    "#from PIL import Image\n",
    "#import requests\n",
    "#requests.__version__\n",
    "#!pip install requests==2.27.1\n",
    "!pip install transformers\n",
    "!pip install wget\n",
    "!pip install lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6OYval8z57_",
    "outputId": "23c7b5a9-809a-4c46-8d84-b31e2095fca8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3qNzGu1rNn4"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('/content/drive/MyDrive/teses/tese_MECD/implementation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJxeT39EFCsv",
    "outputId": "64f01045-5f7d-4217-8e7f-1b91f6a9d03d"
   },
   "outputs": [],
   "source": [
    "%cd '/content/drive/MyDrive/teses/tese_MECD/implementation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBVe8SacTipw"
   },
   "outputs": [],
   "source": [
    "#url = \"./data/flickr30k_images/flickr30k_images/5897297135.jpg\"\n",
    "#os.path.isfile(url)\n",
    "#os.path.isfile('./data/flickr30k_images/flickr30k_images/4852389235.jpg')\n",
    "#image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jeQR8UHvrOAx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import LxmertTokenizer, LxmertConfig, LxmertModel\n",
    "from modeling_frcnn import GeneralizedRCNN\n",
    "import utils\n",
    "from processing_image import Preprocess\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import lmdb\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mg4viCI90XBP"
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,path,image_path,device):\n",
    "        self.device = device\n",
    "        self.path = path\n",
    "        self.size = self.getSize()\n",
    "        self.env = lmdb.open(\n",
    "            path, readonly=True, create=False, readahead=not False\n",
    "        )\n",
    "        self.txn = self.env.begin(buffers=True)\n",
    "        self.image_path = image_path\n",
    "        self.img_env = lmdb.open(\n",
    "            self.image_path, readonly=True, create=False, readahead=not False\n",
    "        )\n",
    "        self.img_txn = self.img_env.begin(buffers=True)\n",
    "\n",
    "    \n",
    "    def getSize(self):\n",
    "        env = lmdb.open(self.path, readonly=True)\n",
    "        stats = env.stat()\n",
    "        count = stats['entries']\n",
    "        env.close()\n",
    "        return count\n",
    "    \n",
    "    def deserializeItem(self,item):\n",
    "        item = pickle.loads(item)\n",
    "        item['input_ids']=torch.tensor(item['input_ids'][0], dtype = torch.int32, device = self.device)\n",
    "        item['attention_mask']=torch.tensor(item['attention_mask'][0], dtype = torch.int32, device = self.device)\n",
    "        item['token_type_ids']=torch.tensor(item['token_type_ids'][0], dtype = torch.int32, device = self.device)\n",
    "        item_img = pickle.loads(self.img_txn.get(item['img'].encode()))\n",
    "        item['normalized_boxes']=torch.tensor(item_img['normalized_boxes'][0], dtype = torch.float32, device = self.device)\n",
    "        item['features']=torch.tensor(item_img['features'][0], dtype = torch.float32, device = self.device)\n",
    "        item['label']=torch.tensor(item['label'], device = self.device)\n",
    "        return item\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.txn.get(str(idx).encode())\n",
    "        item = self.deserializeItem(item)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __exit__(self):\n",
    "        self.img_env.close()\n",
    "        self.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8L7UMGYM02N1"
   },
   "outputs": [],
   "source": [
    "class MyTrainer():\n",
    "    def __init__(self,model,train,eval_test, numb_labels = 3):\n",
    "        self.model = model\n",
    "        self.train = train\n",
    "        self.eval_test = eval_test\n",
    "        self.test_acc_list = []#init\n",
    "        self.model_path = \"my_model_epoch_\"\n",
    "        self.num_labels = numb_labels\n",
    "        self.config_problem_type = \"single_label_classification\"\n",
    "        if self.config_problem_type == \"single_label_classification\":\n",
    "          self.loss_fct = torch.nn.CrossEntropyLoss()\n",
    "          self.output_loss = lambda output,labels : self.loss_fct(output.logits.view(-1, self.num_labels), labels.view(-1)) \n",
    "        elif self.config_problem_type == \"regression\":\n",
    "          self.loss_fct = torch.nn.MSELoss()\n",
    "          if self.num_labels == 1: self.output_loss = lambda output,labels : self.loss_fct(output.logits.squeeze(), labels.squeeze())\n",
    "          else: self.output_loss =  lambda output,labels : self.loss_fct(output.logits, labels)\n",
    "        elif self.config_problem_type == \"multi_label_classification\":\n",
    "          self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "          self.output_loss = lambda output,labels : self.loss_fct(output.logits, labels)\n",
    "\n",
    "    def train_model(self,batch_size = None, lr= None, epochs=None):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=lr)\n",
    "        train_loader = DataLoader(self.train, batch_size=batch_size, shuffle=True)\n",
    "        for epoch in range(epochs):\n",
    "            for item in train_loader:\n",
    "                start = time.time()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model.forward(item)\n",
    "                label = item['label']\n",
    "                loss = self.output_loss(outputs, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                end = time.time()\n",
    "                print(end - start)\n",
    "            print(\"Saving model ....\")\n",
    "            model.save_model(self.model_path+str(epoch))\n",
    "            print(\"Model Saved!\")\n",
    "            test_acc = self.eval_test.evaluate(batch_size = batch_size)\n",
    "            self.test_acc_list.append(test_acc)\n",
    "            print('--- Epoch ',epoch,' Acc: ',test_acc)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "x6eWzMzGs_MQ"
   },
   "outputs": [],
   "source": [
    "class MyEvaluator():\n",
    "  def __init__(self,model,test):\n",
    "    self.test_dataset = test\n",
    "    self.model = model\n",
    "  \n",
    "  def evaluate(self, batch_size = 8):\n",
    "      self.model.eval()\n",
    "      loader = DataLoader(self.test_dataset, batch_size=batch_size)\n",
    "      n_correct = 0\n",
    "      n_possible = 0\n",
    "      for item in loader:\n",
    "        y_hat = self.model.predict(item)\n",
    "        y = item['label']\n",
    "        n_correct += (y == y_hat).sum().item()\n",
    "        n_possible += float(y.shape[0])\n",
    "      self.model.train()\n",
    "      return n_correct / n_possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "D429P3rO1zgq"
   },
   "outputs": [],
   "source": [
    "class Lxmert(LxmertModel):\n",
    "    def __init__(self,numb_labels=3):\n",
    "        super().__init__(LxmertConfig.from_pretrained(\"unc-nlp/lxmert-base-uncased\"))\n",
    "        self.num_labels = numb_labels\n",
    "        self.classification = torch.nn.Linear(self.config.hidden_size, self.num_labels)\n",
    "        # don't forget to init the weights for the new layers\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self,item):       \n",
    "        input_ids = item['input_ids']\n",
    "        attention_mask=item['attention_mask']\n",
    "        token_type_ids=item['token_type_ids']\n",
    "        features = item['features']\n",
    "        normalized_boxes = item['normalized_boxes']\n",
    "        \n",
    "        output = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            visual_feats=features,\n",
    "            visual_pos=normalized_boxes,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=True,\n",
    "            output_attentions=False,\n",
    "        )\n",
    "        \n",
    "        output.logits = self.classification(output.pooled_output)\n",
    "        return output\n",
    "    \n",
    "    def predict(self,item):\n",
    "      \"\"\"\n",
    "      item (n_examples x n_features)\n",
    "      \"\"\"\n",
    "      scores = model(item)  # (n_examples x n_classes)\n",
    "      predicted_labels = scores.logits.argmax(dim=-1)  # (n_examples)\n",
    "      return predicted_labels\n",
    "\n",
    "    def save_model(self,path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load_model(self,path):\n",
    "        self.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykMFdgi72_t4",
    "outputId": "4ea2ef98-ad84-4419-9291-9fa503664418"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "task = 'train'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPvyCltL3Fhy",
    "outputId": "476dcb63-c8f7-4883-b616-3118e1c861c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Training Model-----\n",
      "20.82525873184204\n",
      "22.463051080703735\n",
      "15.623872995376587\n",
      "15.226142883300781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_15900/1964467734.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_evaluator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----Training Model-----\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'----Training finished-----'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mdev_evaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_15900/853543022.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, batch_size, lr, epochs)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_15900/4270108851.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mnormalized_boxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'normalized_boxes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         output = super().forward(\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IST_DL21_Env\\lib\\site-packages\\transformers\\models\\lxmert\\modeling_lxmert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, visual_feats, visual_pos, attention_mask, visual_attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m         \u001b[1;31m# Run Lxmert encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             \u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IST_DL21_Env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IST_DL21_Env\\lib\\site-packages\\transformers\\models\\lxmert\\modeling_lxmert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, lang_feats, lang_attention_mask, visual_feats, visual_pos, visual_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;31m# Run language layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[0ml_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang_feats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m             \u001b[0mlang_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             \u001b[0mlanguage_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlanguage_hidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlang_feats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IST_DL21_Env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IST_DL21_Env\\lib\\site-packages\\transformers\\models\\lxmert\\modeling_lxmert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IST_DL21_Env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IST_DL21_Env\\lib\\site-packages\\transformers\\models\\lxmert\\modeling_lxmert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_tensor, attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;31m# Self attention attends to itself, thus keys and queries are the same (input_tensor).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         output = self.self(\n\u001b[0m\u001b[0;32m    412\u001b[0m             \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IST_DL21_Env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IST_DL21_Env\\lib\\site-packages\\transformers\\models\\lxmert\\modeling_lxmert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, context, attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IST_DL21_Env\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1816\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1818\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1819\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1820\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = MyDataset(\"my_train_db\",\n",
    "                      \"my_image_db\",\n",
    "                      device)\n",
    "test = MyDataset(\"my_test_db\",\n",
    "                      \"my_image_db\",\n",
    "                      device)\n",
    "dev = MyDataset(\"my_dev_db\",\n",
    "                      \"my_image_db\",\n",
    "                      device)\n",
    "if task =='train':\n",
    "    model = Lxmert()\n",
    "    model = model.to(device)\n",
    "    test_evaluator = MyEvaluator(model,test)\n",
    "    trainer = MyTrainer(model,train,test_evaluator)\n",
    "    print(\"-----Training Model-----\")\n",
    "    trainer.train_model(epochs=15,batch_size = 10, lr = 1e-3)\n",
    "    print('----Training finished-----')\n",
    "    dev_evaluator = MyEvaluator(model,dev)\n",
    "    dev_acc = dev_evaluator.evaluate(batch_size = 10)\n",
    "    print(\"---- Dev Acc: \",dev_acc)\n",
    "elif task =='test':\n",
    "    model = Lxmert()\n",
    "    model.load_model(\"my_model\")\n",
    "    model = model.to(device)\n",
    "    evaluator = MyEvaluator(model,dev)\n",
    "    acc = evaluator.evaluate(batch_size = 10)\n",
    "    print(acc)\n",
    "    #output = run_example(model,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6nAUDsM9egGP",
    "outputId": "dde1aa30-606b-4d10-b399-f21eee8a3f75"
   },
   "outputs": [],
   "source": [
    "#%reset\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "from numba import cuda \n",
    "dev = cuda.get_current_device()\n",
    "dev.reset()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uC3nwfhOHPeD"
   },
   "outputs": [],
   "source": [
    "def run_example(model):\n",
    "    data_path = '/content/drive/MyDrive/teses/tese_MECD/implementation/data/'\n",
    "    train = pd.read_csv(data_path+'esnlive_train.csv')\n",
    "    labels_encoding = {'contradiction':0,'neutral': 1,\n",
    "                       'entailment':2}\n",
    "    train['gold_label']=train['gold_label'].apply(lambda label: labels_encoding[label])\n",
    "    img_path = data_path+'flickr30k_images/flickr30k_images/'+ train.loc[50,'Flickr30kID']#\"32542645.jpg\"\n",
    "    question = train.loc[50,'hypothesis'] #\"How many people are in the image?\"\n",
    "    label = train.loc[50,'gold_label']\n",
    "    \n",
    "    lxmert_tokenizer = LxmertTokenizer.from_pretrained(\"unc-nlp/lxmert-base-uncased\")\n",
    "    rcnn_cfg = utils.Config.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\")\n",
    "    rcnn = GeneralizedRCNN.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\", config=rcnn_cfg)\n",
    "    image_preprocess = Preprocess(rcnn_cfg)\n",
    "    \n",
    "    images, sizes, scales_yx = image_preprocess(img_path)\n",
    "    \n",
    "    #preprocess image\n",
    "    output_dict = rcnn(\n",
    "        images, \n",
    "        sizes, \n",
    "        scales_yx=scales_yx, \n",
    "        padding=\"max_detections\",\n",
    "        max_detections=rcnn_cfg.max_detections,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    #preprocess text\n",
    "    inputs = lxmert_tokenizer(\n",
    "        question,\n",
    "        padding=\"max_length\",\n",
    "        max_length=20,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    #Very important that the boxes are normalized\n",
    "    normalized_boxes = output_dict.get(\"normalized_boxes\")\n",
    "    features = output_dict.get(\"roi_features\")\n",
    "    item = {'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            'token_type_ids': inputs['token_type_ids'],\n",
    "            'features':features, \n",
    "            'normalized_boxes':normalized_boxes, \n",
    "            'label':torch.LongTensor([label])}\n",
    "    output = model.forward(inputs['input_ids'],inputs['attention_mask'],inputs['token_type_ids'],\n",
    "                          features,normalized_boxes,torch.LongTensor([label]))\n",
    "    m = torch.nn.Softmax(dim=1)\n",
    "    probs = m(output.logits)\n",
    "    print(img_path)\n",
    "    print(question)\n",
    "    print(label)\n",
    "    print(probs)\n",
    "    return output\n",
    "\n",
    "run_example(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1XnOaCdpryg"
   },
   "outputs": [],
   "source": [
    "env = lmdb.open(\n",
    "            \"/content/drive/MyDrive/teses/tese_MECD/implementation/data/my_train_db\", readonly=True\n",
    "        )\n",
    "txn = env.begin(buffers=True)\n",
    "item = txn.get(str(10).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqmTotl6o9De",
    "outputId": "380d5eba-fc36-4bdf-f84f-2ebdb17f016f"
   },
   "outputs": [],
   "source": [
    "item=pickle.loads(item)\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OlQGRTpoLim",
    "outputId": "247bbb60-8e8c-4346-cc21-c74515261de8"
   },
   "outputs": [],
   "source": [
    "img_env = lmdb.open(\n",
    "            \"/content/drive/MyDrive/teses/tese_MECD/implementation/data/my_image_db\", readonly=True, create=False, readahead=not False\n",
    "        )\n",
    "img_txn = img_env.begin(buffers=True)\n",
    "item_img = item['img']\n",
    "image = img_txn.get(item_img.encode())\n",
    "image = pickle.loads(image)\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTduG0TJpBD3",
    "outputId": "9512badc-7133-4092-f031-ebe0dbc732df"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "dSK69oLn6rEt",
    "outputId": "35521ca1-4f37-4dd4-cdf7-4c7ea84bbb6c"
   },
   "outputs": [],
   "source": [
    "path = \"/content/drive/MyDrive/teses/tese_MECD/implementation/my_model_epoch_\"\n",
    "epoch = 1\n",
    "path+str(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hh8XvAaXDKXR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lxmert_features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
